{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\npd.set_option('display.max_columns', 300)\npd.set_option('display.max_rows', 300)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_curve, log_loss\nfrom skopt import BayesSearchCV\nfrom skopt.space import Integer, Real\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom MLFeatureSelection import FeatureSelection as FS\nimport lightgbm as lgb\nimport gc\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"7683e1e43692641b8728ba00af47e2f27ba468e6","collapsed":true,"_cell_guid":"c2704444-9c97-4285-b616-98a7c41d1b74","trusted":true},"cell_type":"code","source":"feature_columns = ['f%s' % i for i in range(1, 298)]\ndtype = {}\nfor i in feature_columns:\n    if i not in ['f5', 'f82', 'f83', 'f84', 'f85', 'f86']:\n        dtype[i] = 'int16'\ndtype.update({'f5':'int32', 'f82':'float32', 'f83':'float32', \n              'f84':'float32', 'f85':'float32', 'f86':'float32', 'id':'str', 'date':'int16'})","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/anti-preprocess/train.csv.gz', low_memory=True, dtype=dtype, compression='gzip')\ntrain['label'] = train['label'].replace([-1], [1])\ntest = pd.read_csv('../input/anti-preprocess/test.csv.gz', low_memory=True, dtype=dtype, compression='gzip')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb56490b96d6b6daee296178f997735920c44e2b","collapsed":true},"cell_type":"code","source":"grouped = pd.DataFrame((train==-1).sum()).reset_index()\ngrouped.groupby(0).agg(lambda x:', '.join(x))","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"eebc352df3d5758d46d4873ebed9d500f6ee00cc"},"cell_type":"code","source":"pos = train[train['label'] == 1]\nneg = train[train['label'] == 0]\nSAMPLE_NUM = pos.shape[0]\nbalance = pd.concat([pos, neg.sample(SAMPLE_NUM, random_state=10)])\n\nbalance.replace([-1], [0], inplace=True)\ntest.replace([-1], [0], inplace=True)\n\nbalance.sort_index(inplace=True)\nbalance.reset_index(drop=True, inplace=True)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f74191a8e97a9ebc57ff93158b95d12299d3fa7"},"cell_type":"code","source":"def score(pred, real): #评分系统，感谢herhert，返回s2\n    return log_loss(pred, real)\n\ndf = balance\n\ndef validation(X, Y, features, clf, lossfunction):\n    totaltest = []\n    kf = StratifiedKFold(n_splits=5, random_state=10, shuffle=True)\n    for train_index, test_index in kf.split(X, Y):\n        X_train, X_test = X.ix[train_index,:][features], X.ix[test_index,:][features]\n        y_train, y_test = Y[train_index], Y[test_index]\n        #clf.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_test, y_test)], eval_metric='logloss', verbose=False,early_stopping_rounds=50)\n        clf.fit(X_train, y_train)\n        totaltest.append(lossfunction(y_test, clf.predict(X_test)))\n    return np.mean(totaltest)\n\ndef add(x,y):\n    return x + y\n\ndef substract(x,y):\n    return x - y\n\ndef times(x,y):\n    return x * y\n\ndef divide(x,y):\n    return (x + 0.001)/(y + 0.001)\n\nCrossMethod = {'+':add,\n               '-':substract,\n               '*':times,\n               '/':divide,}\n\nsf = FS.Select(Sequence = True, Random = False, Cross = False) #初始化选择器，选择你需要的流程\nsf.ImportDF(df, label ='label') #导入数据集以及目标标签\n#sf.ImportCrossMethod(CrossMethod)\nsf.ImportLossFunction(score, direction = 'descend') #导入评价函数以及优化方向\nsf.InitialNonTrainableFeatures(['id','date', 'label']) #初始化不能用的特征\nsf.InitialFeatures(feature_columns) #初始化其实特征组合\nsf.GenerateCol() #生成特征库 （具体该函数变量请参考根目录下的readme）\nsf.SetSample(1, samplemode = 1) #初始化抽样比例和随机过程\nsf.SetTimeLimit(240) #设置算法运行最长时间，以分钟为单位\nsf.clf = lgb.LGBMClassifier(random_state=1, num_leaves =6, n_estimators=200, max_depth=3, learning_rate = 0.1, n_jobs=4) #设定回归模型\nsf.SetLogFile('record.log') #初始化日志文件\nsf.run(validation) #输入检验函数并开始运行","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"77bc48e8629bf7cf31c0d4385dcace36d2eab655","_cell_guid":"5380c006-3c76-4d90-af0b-16db4724b276","trusted":true,"collapsed":true},"cell_type":"markdown","source":"search_params = {\n    'boosting_type': ['gbdt'],\n    'objective': ['binary'],\n    'metric': ['auc'],\n    'max_depth': Integer(2, 10),\n    'num_leaves': Integer(4, 60),\n    'learning_rate': Real(0.001, 0.08),\n    'feature_fraction': Real(0.1, 1.),         \n    'bagging_fraction': Real(0.1, 1),\n    'bagging_freq': Integer(2, 20),\n    'num_threads': [-1],\n    'num_iterations': Integer(40, 300),\n    'min_child_samples': Integer(5, 100),#adding params, default:20\n    'min_child_weight': Real(.000001, 0.1,),#adding params, default:1e-3\n    'max_bin':Integer(50, 200),\n    #'scale_pos_weight':Integer(1, 100),\n    \n}\nbayes_cv_tuner = BayesSearchCV(\n    estimator = lgb.LGBMClassifier(objective='binary', metric='auc', n_jobs=-1, verbose=0),\n    search_spaces = search_params,    \n    scoring = 'roc_auc',\n    cv =StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n    n_jobs = 1,\n    n_iter = 20,   \n    verbose = 3,\n    refit = False,\n    random_state = 50)\ndef status_print(optim_result):\n    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n    \n    # Get all the models tested so far in DataFrame format\n    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n    \n    # Get current parameters and the best parameters    \n    best_params = pd.Series(bayes_cv_tuner.best_params_)\n    print('Model #{}\\nBest auc: {}\\nBest params: {}\\n'.format(\n        len(all_models),\n        np.round(bayes_cv_tuner.best_score_, 5),\n        bayes_cv_tuner.best_params_\n    ))\n# Fit the model\nresult = bayes_cv_tuner.fit(X, Y, callback=status_print)"},{"metadata":{"_uuid":"5e7eb2182490a559a96d87110c1e1fdd8d49f74e"},"cell_type":"markdown","source":"Model #11\n\nBest auc: 0.98071\n\nBest params: {'bagging_fraction': 0.46688427510068276, 'bagging_freq': 3, 'boosting_type': 'gbdt', 'feature_fraction': 0.76121943556429772, 'learning_rate': 0.066139890726866046, 'max_bin': 153, 'max_depth': 9, 'metric': 'auc', 'min_child_samples': 24, 'min_child_weight': 0.047370946628263792, 'num_iterations': 221, 'num_leaves': 22, 'num_threads': -1, 'objective': 'binary'}\n"},{"metadata":{"_uuid":"333485e0583fd603e4ec10c73c25c1c2eb24db89"},"cell_type":"markdown","source":"params_op = {'bagging_fraction': 0.46688427510068276, \n                 'bagging_freq': 3, \n                 'boosting_type': 'gbdt', \n                 'feature_fraction': 0.76121943556429772, \n                 'learning_rate': 0.066139890726866046, \n                 'max_bin': 153, \n                 'max_depth': 9, \n                 'metric': 'auc', \n                 'min_child_samples': 24, \n                 'min_child_weight': 0.047370946628263792, \n                 'num_iterations': 140, \n                 'num_leaves': 22, \n                 'num_threads': -1, \n                 'objective': 'binary'}\ndtrain = lgb.Dataset(X, Y)\nresult = lgb.cv(params_op, dtrain, metrics='auc', early_stopping_rounds=5, verbose_eval=5)"},{"metadata":{"_uuid":"6c02f7a60fab956d4e111fb92b053bf214d3706e"},"cell_type":"markdown","source":"result2 = lgb.cv(params_op, dtrain, num_boost_round=400, metrics='binary', early_stopping_rounds=5, verbose_eval=5)"},{"metadata":{"_uuid":"762a121d2ddc7e504f4cc1a7f56462f2dca4cf22","_cell_guid":"143c979e-f3a4-47a4-aaf6-49a9af9dd353","trusted":true,"collapsed":true},"cell_type":"code","source":"NFOLDS = 5\nkf = StratifiedKFold(n_splits=NFOLDS, random_state=10, shuffle=True)","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"ad6f77d9968cc6030d43e57a9140769bcceebad7","collapsed":true,"_cell_guid":"3d5db16f-6faf-4ca1-a8d5-6c59086fd41f","trusted":true},"cell_type":"code","source":"def get_oof():\n    oof_train = np.zeros((X.shape[0],))\n    oof_test = np.zeros((X_test.shape[0],))\n    oof_test_skf = np.empty((NFOLDS, X_test.shape[0]))\n    params_op =  {'bagging_fraction': 0.46688427510068276, \n                  'bagging_freq': 3, \n                  'boosting_type': 'gbdt', \n                  'feature_fraction': 0.76121943556429772, \n                  'learning_rate': 0.066139890726866046, \n                  'max_bin': 153, \n                  'max_depth': 9, \n                  'metric': 'auc', \n                  'min_child_samples': 24, \n                  'min_child_weight': 0.047370946628263792, \n                  'num_iterations': 221, \n                  'num_leaves': 40, \n                  'num_threads': -1, \n                  'objective': 'binary'}\n\n    for i, (train_index, test_index) in enumerate(kf.split(X, Y)):\n        x_tr = X.values[train_index]\n        y_tr = Y.values[train_index]\n        x_te = X.values[test_index]\n        \n        dtrain = lgb.Dataset(x_tr, y_tr)\n        model_lgb = lgb.train(params_op, dtrain)\n\n        oof_train[test_index] = model_lgb.predict(x_te)\n        oof_test_skf[i, :] = model_lgb.predict(X_test.values)\n\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)","execution_count":66,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9b5dc7ffbbef3eb36759eba0ff5bbcffbd21c318"},"cell_type":"code","source":"def scorer(y, pred):\n    fpr, tpr, thresholds = roc_curve(y, pred, pos_label=1)\n    score = 0.4 * tpr[np.where(fpr>=0.001)[0][0]] + \\\n            0.3 * tpr[np.where(fpr>=0.005)[0][0]] + \\\n            0.3 * tpr[np.where(fpr>=0.01)[0][0]]\n    print('-----------------------------result------------------------')\n    print('fpr_0.001: {0} | fpr_0.005: {1} | fpr_0.01: {2}'.format(tpr[np.where(fpr>=0.001)[0][0]], \n                                   tpr[np.where(fpr>=0.005)[0][0]], \n                                   tpr[np.where(fpr>=0.01)[0][0]]))\n    print('score : {}'.format(score))\n    return score","execution_count":67,"outputs":[]},{"metadata":{"_uuid":"2a3f277a07718b80c451210dcf79593d54c29079","_cell_guid":"1831b9ad-6c9d-4405-8c81-dbbab30a30fd","trusted":true,"collapsed":true},"cell_type":"markdown","source":"oof_train, oof_test = get_oof() \n#oof['oof_train'] = oof_train\nsubmission['score'] = oof_test\nsubmission.to_csv('lgb_201805261953.csv', index=False)\n#oof.to_csv('oof_all.csv', index=False)"},{"metadata":{"trusted":true,"_uuid":"cdc95638b30ce9a40309fdaaf79bac5f2b28d12e","collapsed":true},"cell_type":"markdown","source":"scorer(Y, oof_train)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"65ed57c4b62fc1bf7d0b098632dd09a6b90ca9a2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}